{"cells":[{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4064,"status":"ok","timestamp":1652028989130,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"D1UOj0r3lhU4","outputId":"a540cfc0-b584-413b-d0e0-957fab149cf5"},"outputs":[{"name":"stderr","output_type":"stream","text":["'gdown' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["!gdown https://drive.google.com/uc?id=1wHRVN7l6quMFTG7seVS0pHh7ULrc78ug"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":30498,"status":"ok","timestamp":1652029021111,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"qLmH-vWHln8e"},"outputs":[],"source":["import pandas as pd\n","from ast import literal_eval\n","from sklearn.metrics import f1_score\n","\n","df = pd.read_csv(\"./subset_genre.csv\")\n","\n","# interpret cols as lists instead of strings\n","for col in ['unigrams', 'sentences', 'lem_sent']: \n","  df[col] = df[col].apply(literal_eval)\n","\n","# idk where the col comes from \n","#df.drop('Unnamed: 0', axis=1, inplace = True)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10749,"status":"ok","timestamp":1652029037099,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"cE-he5kEls42","outputId":"59e853cd-8e0d-4c24-aded-e72712cb56ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\byrom\\anaconda3\\lib\\site-packages (4.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (0.5.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n","Requirement already satisfied: requests in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n","Requirement already satisfied: sacremoses in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (0.0.53)\n","Requirement already satisfied: filelock in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n","Requirement already satisfied: colorama in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: click in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (8.0.3)\n","Requirement already satisfied: joblib in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in c:\\users\\byrom\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":10855,"status":"ok","timestamp":1652029053060,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"2BvdRJvMlvII"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from transformers import BertTokenizer, BertModel\n","from torch import nn\n","from torch.optim import Adam\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":1579,"status":"ok","timestamp":1652029166441,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"XDykwe6alyqK"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","labels = {'drama':0,\n","          'comedy':1,\n","          'action':2,\n","          'thriller':3\n","          }\n","\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        self.labels = [labels[label] for label in df['genre']]\n","        self.texts = [tokenizer(text, \n","                               padding='max_length', max_length = 512, truncation=True,\n","                                return_tensors=\"pt\") for text in df['text']]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_batch_labels(self, idx):\n","        # Fetch a batch of labels\n","        return np.array(self.labels[idx])\n","\n","    def get_batch_texts(self, idx):\n","        # Fetch a batch of inputs\n","        return self.texts[idx]\n","\n","    def __getitem__(self, idx):\n","\n","        batch_texts = self.get_batch_texts(idx)\n","        batch_y = self.get_batch_labels(idx)\n","\n","        return batch_texts, batch_y"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1652029061265,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"FrhKXXjnl-E_"},"outputs":[],"source":["class BertClassifier(nn.Module):\n","\n","    def __init__(self, dropout=0.5):\n","\n","        super(BertClassifier, self).__init__()\n","\n","        self.bert = BertModel.from_pretrained('bert-base-cased')\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear = nn.Linear(768, 4)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, input_id, mask):\n","\n","        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n","        dropout_output = self.dropout(pooled_output)\n","        linear_output = self.linear(dropout_output)\n","        final_layer = self.relu(linear_output)\n","\n","        return final_layer\n"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":327,"status":"ok","timestamp":1652029064963,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"Y-VVF_8rmAed"},"outputs":[],"source":["def train(model, train_data, val_data, learning_rate, epochs):\n","\n","    train, val = Dataset(train_data), Dataset(val_data)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n","    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr= learning_rate)\n","\n","    if use_cuda:\n","\n","            model = model.cuda()\n","            criterion = criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","\n","            total_acc_train = 0\n","            total_loss_train = 0\n","\n","            for train_input, train_label in tqdm(train_dataloader):\n","\n","                train_label = train_label.type(torch.LongTensor)\n","                train_label = train_label.to(device)\n","                mask = train_input['attention_mask'].to(device)\n","                input_id = train_input['input_ids'].squeeze(1).to(device)\n","\n","                output = model(input_id, mask)\n","                \n","                batch_loss = criterion(output, train_label)\n","                total_loss_train += batch_loss.item()\n","                \n","                acc = (output.argmax(dim=1) == train_label).sum().item()\n","                total_acc_train += acc\n","\n","                model.zero_grad()\n","                batch_loss.backward()\n","                optimizer.step()\n","            \n","            total_acc_val = 0\n","            total_loss_val = 0\n","\n","            with torch.no_grad():\n","\n","                for val_input, val_label in val_dataloader:\n","\n","                    val_label = val_label.type(torch.LongTensor)\n","                    val_label = val_label.to(device)\n","                    mask = val_input['attention_mask'].to(device)\n","                    input_id = val_input['input_ids'].squeeze(1).to(device)\n","\n","                    output = model(input_id, mask)\n","\n","                    batch_loss = criterion(output, val_label)\n","                    total_loss_val += batch_loss.item()\n","                    \n","                    acc = (output.argmax(dim=1) == val_label).sum().item()\n","                    total_acc_val += acc\n","            \n","            print(\n","                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n","                  "]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":147,"status":"ok","timestamp":1652029070112,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"hQqUfzm9mDsC"},"outputs":[],"source":["def evaluate(model, test_data):\n","\n","    test = Dataset(test_data)\n","\n","    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","\n","        model = model.cuda()\n","\n","    total_acc_test = 0\n","    test_f1 = 0.0\n","    batch_cnt = 0\n","\n","    with torch.no_grad():\n","\n","        for test_input, test_label in test_dataloader:\n","\n","              test_label = test_label.to(device)\n","              mask = test_input['attention_mask'].to(device)\n","              input_id = test_input['input_ids'].squeeze(1).to(device)\n","\n","              output = model(input_id, mask)\n","\n","              acc = (output.argmax(dim=1) == test_label).sum().item()\n","              total_acc_test += acc\n","\n","              y_pred = output.argmax(dim=1)\n","              test_f1 += f1_score(test_label.cpu().detach().numpy(), y_pred.cpu().detach().numpy(), average = 'weighted')\n","              batch_cnt += 1\n","    \n","    print(f'Test F1: {test_f1/batch_cnt}')\n","    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":125,"status":"ok","timestamp":1652029080204,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"oh6J2AJ0mHFH"},"outputs":[],"source":["df_new = df"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":129,"status":"ok","timestamp":1652029083379,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"QinivEktmKoR"},"outputs":[],"source":["# def get_drama_comedy_action_thriller(genres):\n","#   for gen in genres:\n","#     if gen==\"drama\":\n","#       return gen\n","#     elif gen==\"comedy\":\n","#       return gen\n","#     elif gen==\"action\":\n","#       return gen\n","#     elif gen==\"thriller\":\n","#       return gen\n","#     else:\n","#       return 0\n","\n","# df_new[\"genre_new\"] = df_new.genres.apply(get_drama_comedy_action_thriller)"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1652029086033,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"Mnd_tvmrmOLO"},"outputs":[],"source":["#df_new2 = df_new[df_new[\"genre_new\"] != 0]"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1652029087242,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"xK09mLsFmQ8j"},"outputs":[],"source":["# df_drama = df_new2[df_new2[\"genre_new\"] == \"drama\"]\n","# df_drama_subset = df_drama.sample(500)\n","\n","# df_comedy = df_new2[df_new2[\"genre_new\"] == \"comedy\"]\n","# df_comedy_subset = df_comedy.sample(500)\n","\n","# df_action = df_new2[df_new2[\"genre_new\"] == \"action\"]\n","# df_action_subset = df_action.sample(500)\n","\n","# df_thriller = df_new2[df_new2[\"genre_new\"] == \"thriller\"]\n","# df_thriller_subset = df_thriller.sample(500)"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":170,"status":"ok","timestamp":1652029096053,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"LDgHH3e4miVV"},"outputs":[],"source":["# df_concat = pd.concat([df_drama_subset, df_comedy_subset, df_action_subset, df_thriller_subset])\n","# print(df_concat)"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":127,"status":"ok","timestamp":1652029098863,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"yzFIcNJYm34P"},"outputs":[],"source":["# def flatten_sent(sentences):\n","#   return [\" \".join(sent) for sent in sentences]\n","\n","# df[\"lem_sent_join\"] = df.lem_sent.apply(flatten_sent)"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":173,"status":"ok","timestamp":1652029120531,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"v1yQjNgxm5T8"},"outputs":[],"source":["# def make_string(sentences):\n","#   return \" \".join(sentences)\n","\n","# df['text'] = df.lem_sent_join.apply(make_string)"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1652029142013,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"o1SII6rbm55m","outputId":"3cb51fc2-1cba-4a96-9c6f-4cc60b6db356"},"outputs":[{"name":"stdout","output_type":"stream","text":["5582 698 698\n"]}],"source":["import numpy as np\n","\n","np.random.seed(112)\n","df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n","                                     [int(.8*len(df)), int(.9*len(df))])\n","\n","print(len(df_train),len(df_val), len(df_test))"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512,"referenced_widgets":["61f9b2fc894743da9af6760208597f4a","7d2dfcab2be944f6888db2f9cc421b46","c10e811ca1d14e2f834f83ba0c62516e","2c0d3ffe5dbf40db93adc9c2e89ae2c3","db3ac7f4cd4249b1b2a2cd8150f2e48b","ce5048f8d1cc4631b49b0cf599447d2d","6461bcfcc88942128b5aacd7a69664e7","818f4387460148a391c4b905320d9e98","1311a2a7b2784905a47cb49375dffa5b","1020a4f77b2545ef8c0887758d73e227","e936d354db4d40cab2540b79bd48b6e0"]},"executionInfo":{"elapsed":43865,"status":"error","timestamp":1652029228373,"user":{"displayName":"Izabella Rivera","userId":"16648284813707499159"},"user_tz":240},"id":"16otUAqVnDE2","outputId":"02ffb082-0939-47d6-9642-5782432dc960"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 2791/2791 [10:26<00:00,  4.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 1 | Train Loss:  0.662 | Train Accuracy:  0.365 | Val Loss:  0.543 | Val Accuracy:  0.583\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2791/2791 [10:26<00:00,  4.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 2 | Train Loss:  0.498 | Train Accuracy:  0.618 | Val Loss:  0.457 | Val Accuracy:  0.650\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2791/2791 [10:29<00:00,  4.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 3 | Train Loss:  0.433 | Train Accuracy:  0.677 | Val Loss:  0.423 | Val Accuracy:  0.668\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2791/2791 [10:36<00:00,  4.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 4 | Train Loss:  0.374 | Train Accuracy:  0.729 | Val Loss:  0.406 | Val Accuracy:  0.679\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2791/2791 [10:37<00:00,  4.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 5 | Train Loss:  0.321 | Train Accuracy:  0.778 | Val Loss:  0.413 | Val Accuracy:  0.692\n","Test F1: 0.6943648519579753\n","Test Accuracy:  0.698\n"]}],"source":["EPOCHS = 5\n","model = BertClassifier()\n","LR = 1e-6\n","              \n","train(model, df_train, df_val, LR, EPOCHS)\n","\n","evaluate(model, df_test)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test F1: 0.6929321872015282\n","Test Accuracy:  0.695\n"]}],"source":["evaluate(model, df_test)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPTgPULaZZXKZSSZ49pLQEE","name":"BERT.ipynb","provenance":[]},"interpreter":{"hash":"baa205e2e9050fda66e8fac9696da9a2d8425efd3bf2c0fb946d46c225b2ed39"},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1020a4f77b2545ef8c0887758d73e227":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1311a2a7b2784905a47cb49375dffa5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c0d3ffe5dbf40db93adc9c2e89ae2c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1020a4f77b2545ef8c0887758d73e227","placeholder":"​","style":"IPY_MODEL_e936d354db4d40cab2540b79bd48b6e0","value":" 416M/416M [00:08&lt;00:00, 55.1MB/s]"}},"61f9b2fc894743da9af6760208597f4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d2dfcab2be944f6888db2f9cc421b46","IPY_MODEL_c10e811ca1d14e2f834f83ba0c62516e","IPY_MODEL_2c0d3ffe5dbf40db93adc9c2e89ae2c3"],"layout":"IPY_MODEL_db3ac7f4cd4249b1b2a2cd8150f2e48b"}},"6461bcfcc88942128b5aacd7a69664e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d2dfcab2be944f6888db2f9cc421b46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce5048f8d1cc4631b49b0cf599447d2d","placeholder":"​","style":"IPY_MODEL_6461bcfcc88942128b5aacd7a69664e7","value":"Downloading: 100%"}},"818f4387460148a391c4b905320d9e98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c10e811ca1d14e2f834f83ba0c62516e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_818f4387460148a391c4b905320d9e98","max":435779157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1311a2a7b2784905a47cb49375dffa5b","value":435779157}},"ce5048f8d1cc4631b49b0cf599447d2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db3ac7f4cd4249b1b2a2cd8150f2e48b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e936d354db4d40cab2540b79bd48b6e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
